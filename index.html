<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Batch Document/Photo Scanner (Single File)</title>
  <style>
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,'Helvetica Neue',Arial;margin:12px;color:#111}
    h1{font-size:18px;margin:0 0 8px}
    .row{display:flex;gap:12px;flex-wrap:wrap}
    video,canvas{border-radius:6px;border:1px solid #ccc}
    #controls{display:flex;gap:8px;align-items:center;margin:8px 0}
    button,input[type=file]{padding:8px 10px;border-radius:6px;border:1px solid #888;background:#f5f5f5;cursor:pointer}
    #thumbs{display:flex;flex-wrap:wrap;gap:8px;margin-top:12px}
    .thumb{display:flex;flex-direction:column;align-items:center;padding:6px;border:1px solid #ddd;border-radius:6px;background:#fff}
    .thumb img{max-width:200px;max-height:160px;display:block;margin-bottom:6px}
    label.input{display:flex;gap:8px;align-items:center}
    input[type=range]{width:160px}
    small{color:#666}
  </style>
</head>
<body>
  <h1>Batch Document / Photo Scanner — single HTML file</h1>
  <p>Use your camera or upload an existing image. Capture one photo, then press <strong>Process</strong> to detect, extract and download each rectangle.</p>

  <div class="row">
    <video id="video" width="480" height="360" autoplay playsinline></video>
    <canvas id="canvasPreview" width="480" height="360" style="display:none"></canvas>
  </div>

  <div id="controls">
    <button id="btnStart">Start Camera</button>
    <button id="btnCapture" disabled>Capture</button>
    <input type="file" id="fileInput" accept="image/*">
    <button id="btnProcess" disabled>Process</button>
    <button id="btnClear">Clear</button>
    <label class="input"><small>Min area</small><input id="minArea" type="range" min="2000" max="200000" value="4000"></label>
    <label class="input"><small>Approx epsilon (%)</small><input id="eps" type="range" min="1" max="20" value="5"></label>
  </div>

  <div id="thumbs"></div>

  <script src="https://docs.opencv.org/4.x/opencv.js"></script>
  <script>
    let cvReady = false;
    let video = document.getElementById('video');
    let canvasPreview = document.getElementById('canvasPreview');
    let ctx = canvasPreview.getContext('2d');
    let stream = null;
    let lastImage = null;

    const btnStart = document.getElementById('btnStart');
    const btnCapture = document.getElementById('btnCapture');
    const btnProcess = document.getElementById('btnProcess');
    const btnClear = document.getElementById('btnClear');
    const fileInput = document.getElementById('fileInput');
    const thumbs = document.getElementById('thumbs');
    const minArea = document.getElementById('minArea');
    const eps = document.getElementById('eps');

    // OpenCV runtime ready
    cv['onRuntimeInitialized'] = () => {
      cvReady = true;
      console.log('OpenCV loaded');
    };

    btnStart.onclick = async ()=>{
      try{
        if(stream) { // stop
          stream.getTracks().forEach(t=>t.stop());
          stream = null;
          video.srcObject = null;
          btnStart.textContent = 'Start Camera';
          btnCapture.disabled = true;
          btnProcess.disabled = true;
          return;
        }
        stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'environment'}, audio:false});
        video.srcObject = stream;
        btnStart.textContent = 'Stop Camera';
        btnCapture.disabled = false;
      }catch(e){
        alert('Camera permission denied or no camera available.\n' + e);
      }
    }

    btnCapture.onclick = ()=>{
      canvasPreview.width = video.videoWidth || 640;
      canvasPreview.height = video.videoHeight || 480;
      ctx.drawImage(video,0,0,canvasPreview.width,canvasPreview.height);
      lastImage = ctx.getImageData(0,0,canvasPreview.width,canvasPreview.height);
      btnProcess.disabled = false;
      thumbs.innerHTML = '';
    }

    // load image from file
    fileInput.onchange = e=>{
      if(!e.target.files.length) return;
      const file = e.target.files[0];
      const reader = new FileReader();
      reader.onload = function(ev){
        const img = new Image();
        img.onload = ()=>{
          canvasPreview.width = img.width;
          canvasPreview.height = img.height;
          ctx.drawImage(img,0,0);
          lastImage = ctx.getImageData(0,0,canvasPreview.width,canvasPreview.height);
          btnProcess.disabled = false;
          thumbs.innerHTML = '';
        };
        img.src = ev.target.result;
      };
      reader.readAsDataURL(file);
    };

    btnClear.onclick = ()=>{
      thumbs.innerHTML = '';
      lastImage = null;
      btnProcess.disabled = true;
    }

    btnProcess.onclick = ()=>{
      if(!lastImage) return alert('Capture or upload an image first');
      if(!cvReady) return alert('OpenCV not loaded yet — wait a second and try again');
      processImage();
    }

    function sortContoursByPosition(items){
      items.sort((a,b)=>{
        let ay = a.centroid.y, by = b.centroid.y;
        if(Math.abs(ay-by) > 20) return ay - by;
        return a.centroid.x - b.centroid.x;
      });
    }

    function distance(a,b){let dx=a.x-b.x,dy=a.y-b.y;return Math.sqrt(dx*dx+dy*dy);}
    function indexOfMin(arr){return arr.indexOf(Math.min.apply(null,arr));}
    function indexOfMax(arr){return arr.indexOf(Math.max.apply(null,arr));}
    function orderQuadPoints(pts){
      let sum = pts.map(p=>p.x+p.y);
      let diff = pts.map(p=>p.y - p.x);
      let tl = pts[indexOfMin(sum)];
      let br = pts[indexOfMax(sum)];
      let tr = pts[indexOfMin(diff)];
      let bl = pts[indexOfMax(diff)];
      return [tl,tr,br,bl];
    }

    function processImage(){
      let src = cv.matFromImageData(lastImage);
      let gray = new cv.Mat();
      cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
      let blur = new cv.Mat();
      cv.GaussianBlur(gray, blur, new cv.Size(5,5), 0);
      let edged = new cv.Mat();
      cv.Canny(blur, edged, 50, 150);
      let kernel = cv.Mat.ones(3,3,cv.CV_8U);
      cv.dilate(edged, edged, kernel);
      cv.erode(edged, edged, kernel);

      let contours = new cv.MatVector();
      let hierarchy = new cv.Mat();
      cv.findContours(edged, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);

      let found = [];
      for(let i=0;i<contours.size();i++){
        let cnt = contours.get(i);
        let area = cv.contourArea(cnt);
        if(area < Number(minArea.value)) { cnt.delete(); continue; }
        let peri = cv.arcLength(cnt, true);
        let approx = new cv.Mat();
        let epsFactor = Number(eps.value)/100.0;
        cv.approxPolyDP(cnt, approx, epsFactor * peri, true);
        if(approx.rows === 4){
          let moments = cv.moments(cnt, false);
          let cx = moments.m10/moments.m00 || 0;
          let cy = moments.m01/moments.m00 || 0;
          let pts = [];
          for(let j=0;j<4;j++){
            pts.push({x: approx.intPtr(j,0)[0], y: approx.intPtr(j,0)[1]});
          }
          found.push({contour:cnt, approx:approx, centroid:{x:cx,y:cy}, pts:pts});
        } else { approx.delete(); cnt.delete(); }
      }

      if(found.length===0){
        alert('No rectangles found. Adjust sliders and try again.');
        src.delete();gray.delete();blur.delete();edged.delete();contours.delete();hierarchy.delete();kernel.delete();
        return;
      }

      sortContoursByPosition(found);
      thumbs.innerHTML = '';

      for(let k=0;k<found.length;k++){
        let f = found[k];
        let ordered = orderQuadPoints(f.pts);
        let wA = distance(ordered[2], ordered[3]);
        let wB = distance(ordered[1], ordered[0]);
        let maxW = Math.max(wA, wB);
        let hA = distance(ordered[1], ordered[2]);
        let hB = distance(ordered[0], ordered[3]);
        let maxH = Math.max(hA, hB);
        maxW = Math.max(100, Math.round(maxW));
        maxH = Math.max(100, Math.round(maxH));

        let srcTri = cv.matFromArray(4,1,cv.CV_32FC2,[
          ordered[0].x,ordered[0].y,
          ordered[1].x,ordered[1].y,
          ordered[2].x,ordered[2].y,
          ordered[3].x,ordered[3].y
        ]);
        let dstTri = cv.matFromArray(4,1,cv.CV_32FC2,[
          0,0,
          maxW-1,0,
          maxW-1,maxH-1,
          0,maxH-1
        ]);
        let M = cv.getPerspectiveTransform(srcTri,dstTri);
        let dst = new cv.Mat();
        cv.warpPerspective(src,dst,M,new cv.Size(maxW,maxH),cv.INTER_LINEAR,cv.BORDER_REPLICATE);

        let outCanvas=document.createElement('canvas');
        outCanvas.width=dst.cols;outCanvas.height=dst.rows;
        let outCtx=outCanvas.getContext('2d');
        let img=new ImageData(new Uint8ClampedArray(dst.data),dst.cols,dst.rows);
        outCtx.putImageData(img,0,0);

        let wrapper=document.createElement('div');wrapper.className='thumb';
        let imgEl=document.createElement('img');imgEl.src=outCanvas.toDataURL('image/jpeg',0.9);
        wrapper.appendChild(imgEl);

        let dl=document.createElement('a');
        dl.href=imgEl.src;dl.download=`scan_${k+1}.jpg`;
        dl.textContent='Download';
        dl.style.marginBottom='6px';
        wrapper.appendChild(dl);

        thumbs.appendChild(wrapper);

        M.delete();dst.delete();srcTri.delete();dstTri.delete();
      }

      src.delete();gray.delete();blur.delete();edged.delete();contours.delete();hierarchy.delete();kernel.delete();
      for(let f of found){try{f.contour.delete();f.approx.delete();}catch(e){}}
    }
  </script>
</body>
</html>
